{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the Libraries"
      ],
      "metadata": {
        "id": "U-mttHbF53u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import LSTM\n",
        "from keras import models, layers\n",
        "from keras_visualizer import visualizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, accuracy_score ,specificity_score, roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "metadata": {
        "id": "NePoJbKw52WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Dataset, applying Padding and Splitting the data"
      ],
      "metadata": {
        "id": "-fC5O8nt6G0w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4UOYw0GGqzG"
      },
      "source": [
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 8000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# pad dataset to a maximum review length in words\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "\n",
        "X = numpy.concatenate((X_train, X_test), axis=0)\n",
        "y = numpy.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # split into train and test sets."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the Model Architecture"
      ],
      "metadata": {
        "id": "FWIOA2vn60p_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cHXtj9-Gw2X"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(top_words, 100, input_length=max_words))\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(Conv1D(64, 3, padding='same',activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.8))\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizer(model, file_name=\"lstm_cnn\", file_format=\"png\", view=True)"
      ],
      "metadata": {
        "id": "EVgiOnjLTlKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(\"lstm_cnn.png\")\n",
        "display(img)"
      ],
      "metadata": {
        "id": "dHRYcE5XTlh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model\n"
      ],
      "metadata": {
        "id": "7OfUTuVm7Sa7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgB5YX9rHCGV",
        "outputId": "3f57e1b3-5ee4-4f5f-fb3b-ccae43913999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# fit the model\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=3, batch_size=128, verbose=2)\n",
        "\n",
        "# final evaluation of the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test loss: {loss}')\n",
        "print(f'Test accuracy: {accuracy}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model compiled\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 28000 samples, validate on 7000 samples\n",
            "Epoch 1/3\n",
            " - 489s - loss: 0.4656 - acc: 0.7486 - val_loss: 0.2896 - val_acc: 0.8794\n",
            "Epoch 2/3\n",
            " - 487s - loss: 0.2265 - acc: 0.9134 - val_loss: 0.3021 - val_acc: 0.8777\n",
            "Epoch 3/3\n",
            " - 487s - loss: 0.1712 - acc: 0.9352 - val_loss: 0.2976 - val_acc: 0.8824\n",
            "Accuracy: 88.49%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the Model"
      ],
      "metadata": {
        "id": "YHPwKHAQ7lBw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-XwWNUVBpFQ"
      },
      "source": [
        "pred = model.predict(X_test)\n",
        "pred = [1 if x > 0.5 else 0 for x in pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Classification Report"
      ],
      "metadata": {
        "id": "eVG5ZZ9gT6rO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification Report:')\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "UPGpeVDUT7Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Confusion Matrix"
      ],
      "metadata": {
        "id": "gdRT7DjrT96g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, pred))"
      ],
      "metadata": {
        "id": "SjfVh_a_T-XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Evaluation Metrics"
      ],
      "metadata": {
        "id": "6h37q02xUGVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test, pred)\n",
        "recall = recall_score(y_test, pred)\n",
        "f1 = f1_score(y_test, pred)\n",
        "specificity = specificity_score(y_test, pred)\n",
        "accuracy = accuracy_score(y_test, pred)\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')\n",
        "print(f'Specificity: {specificity}')\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "RKfClepxUIzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ROC Curve"
      ],
      "metadata": {
        "id": "ziz39hUlULQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-YfYwqGfUNBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the Model"
      ],
      "metadata": {
        "id": "5GhTAcgn8VE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"lstm_cnnmodel.h5\")"
      ],
      "metadata": {
        "id": "0dT9KYGT8XDu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}